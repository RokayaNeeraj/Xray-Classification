# -*- coding: utf-8 -*-
"""Xray

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E4zuyXSWf3YBO28yLhp4-KeO8bO9ajKl

# Uploading the folders and files
"""

from google.colab import files
uploaded = files.upload()

"""# Extracting the zip file"""

import zipfile
with zipfile.ZipFile('CovidXRayImages.zip', 'r') as zip_ref:
    zip_ref.extractall('/content')

"""#Data Collection and Processing with Pandas"""

import pandas as pd
import os

root_directory = '/content/Val'

# Create an empty list to store data
data = []

# Define class labels based on your directory structure
class_labels = {
    'COVID-19': 0,
    'Non-COVID': 1,
    'Normal': 2
}

# Loop through the class subdirectories
for class_name, label in class_labels.items():
    class_directory = os.path.join(root_directory, class_name)

    # Loop through the 'lung masks' subfolder in each class
    lung_mask_directory = os.path.join(class_directory, 'lung masks')

    for mask_filename in os.listdir(lung_mask_directory):
        mask_path = os.path.join(lung_mask_directory, mask_filename)

        # Store the numerical class label and lung mask file path in the list
        data.append({
            'class': label,
            'lung_mask_path': mask_path
        })

# Create a DataFrame from the data list
df = pd.DataFrame(data)

# Display the DataFrame
print(df)

"""#Data Visualization and Analysis Functions:"""

import cv2
import pandas as pd
import matplotlib.pyplot as plt

# Visual Inspection
def visual_inspection(df, num_samples=5):
    """Displays a subset of lung masks randomly"""
    samples = df.sample(n=num_samples)

    plt.figure(figsize=(15, num_samples * 3))  # Adjust the figure size

    for idx, (index, row) in enumerate(samples.iterrows()):
        image = cv2.imread(row['lung_mask_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB

        plt.subplot(1, num_samples, idx + 1)
        plt.imshow(image)
        plt.title(row['class'])
        plt.axis('off')

    plt.show()

visual_inspection(df)  # Call this function to see the lung masks

# Distribution Analysis
def distribution_analysis(df):
    """Prints the distribution of classes"""
    print(df['class'].value_counts())

distribution_analysis(df)  # Call this function to see the class distribution

"""From the ouput we can see that there is no class imbalance.

# Data Cleaning and Preprocessing:
"""

import os
import hashlib

# Handling Corrupted Images
def remove_corrupted_images(df):
    """Removes entries of images that can't be opened or have incorrect labels."""
    valid_rows = []

    for idx, row in df.iterrows():
        try:
            # Try to open the image
            image = cv2.imread(row['lung_mask_path'])
            if image is not None:
                valid_rows.append(row)
        except Exception as e:
            print(f"Error with {row['lung_mask_path']}: {e}")

    return pd.DataFrame(valid_rows)

df = remove_corrupted_images(df)

# Removing Duplicates
def remove_duplicate_images(df):
    """Removes duplicate image entries based on image content."""
    image_hashes = {}
    unique_rows = []

    for idx, row in df.iterrows():
        with open(row['lung_mask_path'], 'rb') as f:
            # Hashing the content of the image file
            image_hash = hashlib.md5(f.read()).hexdigest()

            if image_hash not in image_hashes:
                image_hashes[image_hash] = True
                unique_rows.append(row)
            else:
                print(f"Duplicate found: {row['image_path']}")

    return pd.DataFrame(unique_rows)

df = remove_duplicate_images(df)

df

"""# Image Resizing and Preprocessing:"""

import numpy as np
def resize_and_maintain_aspect(image, desired_size):
    """Resize the image to the desired size while maintaining its aspect ratio."""
    old_size = image.shape[:2]  # old_size is in (height, width) format

    # Calculate the ratio of the new image to the original image
    ratio = float(desired_size) / max(old_size)
    new_size = tuple([int(x * ratio) for x in old_size])

    # Resize the image
    resized_image = cv2.resize(image, (new_size[1], new_size[0]))

    # Create a black canvas of the desired size
    canvas = np.zeros((desired_size, desired_size), dtype=image.dtype)

    # Calculate the position to place the resized image on the canvas
    offset_height = (desired_size - new_size[0]) // 2
    offset_width = (desired_size - new_size[1]) // 2

    # Place the resized image at the center of the canvas
    canvas[offset_height:offset_height + new_size[0], offset_width:offset_width + new_size[1]] = resized_image

    return canvas

def preprocess_images_for_resizing(df, desired_size=224):
    """Resize all images in the dataframe to the desired size while maintaining aspect ratio."""
    for idx, row in df.iterrows():
        image = cv2.imread(row['lung_mask_path'], cv2.IMREAD_GRAYSCALE)
        processed_image = resize_and_maintain_aspect(image, desired_size)
        cv2.imwrite(row['lung_mask_path'], processed_image)

# Call the preprocessing function
preprocess_images_for_resizing(df, desired_size=224)

"""#Image Color Conversion and Normalization"""

def convert_color_space(image, color_space='GRAY'):
    """Convert image to the desired color space."""
    if color_space == 'GRAY':
        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    elif color_space == 'HSV':
        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    elif color_space == 'LAB':
        return cv2.cvtColor(image, cv2.COLOR_BGR2Lab)
    else:
        return image  # Return original if color space is not recognized

def normalize_image(image):
    """Normalize image to [0, 1] range."""
    return image / 255.0

def standardize_image(image):
    """Standardize image to have mean=0 and std=1."""
    mean, std = np.mean(image), np.std(image)
    return (image - mean) / std

def preprocess_images_for_color_and_norm(df, color_space='GRAY'):
    """Convert images to a specified color space and normalize them."""
    for idx, row in df.iterrows():
        image = cv2.imread(row['lung_mask_path'])

        # Convert color space
        converted_image = convert_color_space(image, color_space)

        # Normalize
        normalized_image = normalize_image(converted_image)

        # Standardize
        standardized_image = standardize_image(normalized_image)

        # Save the processed image
        cv2.imwrite(row['lung_mask_path'], (standardized_image * 255).astype(np.uint8))

# Call the preprocessing function
preprocess_images_for_color_and_norm(df, color_space='GRAY')

"""- **`convert_color_space`**: Converts an image to a specified color space (e.g., grayscale, HSV, LAB), extensible to other color spaces.
- **`normalize_image`**: Normalizes pixel values of an image to the range [0, 1].
- **`standardize_image`**: Standardizes pixel values of an image to have a mean of 0 and a standard deviation of 1.
- **`preprocess_images_for_color_and_norm`**: Processes each image in a dataframe by converting it to the specified color space, normalizing it, standardizing it, and then saving the processed image. Adjust the `color_space` parameter to choose the desired color space ('GRAY', 'HSV', or 'LAB').

# Image Preprocessing and Data Augmentation
"""

import cv2
import numpy as np
from keras.preprocessing.image import ImageDataGenerator

# Pixel Value Scaling and Z-Score Normalization
def preprocess_image(image_path):
    """Load image, scale its pixel values to [0, 1], and then apply Z-Score normalization."""
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Pixel Value Scaling
    image = image / 255.0

    # Z-Score Normalization
    image = (image - np.mean(image)) / np.std(image)

    return image

# Data Augmentation
def augment_data(image):
    """Apply data augmentation on the input image."""
    datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

    # Reshape the image to (1, height, width, 1) for the ImageDataGenerator
    image = image.reshape((1,) + image.shape + (1,))

    # Here, just return the first augmented image for simplicity
    # In a real scenario, you'd want to generate a batch and use it for training
    for batch in datagen.flow(image, batch_size=1):
        return batch[0].reshape(image.shape[1:3])

# Sample usage
image_path = df['lung_mask_path'].iloc[0]  # sample image path from your dataframe
processed_image = preprocess_image(image_path)
augmented_image = augment_data(processed_image)

"""- **`convert_color_space`**: Converts images to specified color spaces (e.g., grayscale, HSV, LAB) with extensibility.

- **`normalize_image`**: Normalizes image pixel values to [0, 1] range.

- **`standardize_image`**: Standardizes image pixel values to mean=0 and standard deviation=1.

- **`preprocess_images_for_color_and_norm`**: Processes dataframe images by converting to the chosen color space, normalizing, and standardizing. The `color_space` parameter determines the color space.

1.   List item
2.   List item

# Image Visualization:
"""

import matplotlib.pyplot as plt

def visualize_images(original, processed, augmented):
    """Visualize the original, processed, and augmented images side-by-side."""
    plt.figure(figsize=(15, 5))

    # Original Image
    plt.subplot(1, 3, 1)
    plt.imshow(original, cmap='gray')
    plt.title("Original Image")
    plt.axis('off')

    # Processed Image
    plt.subplot(1, 3, 2)
    plt.imshow(processed, cmap='gray')
    plt.title("Processed Image")
    plt.axis('off')

    # Augmented Image
    plt.subplot(1, 3, 3)
    plt.imshow(augmented, cmap='gray')
    plt.title("Augmented Image")
    plt.axis('off')

    plt.show()

# Load the original image
original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# Visualize
visualize_images(original_image, processed_image, augmented_image)

"""# Image Augmentation and Enhancement:"""

from keras.preprocessing.image import ImageDataGenerator

# Data Augmentation
def augment_image(image):
    """Apply data augmentation techniques on the input image."""
    datagen = ImageDataGenerator(
        rotation_range=40,  # Rotate by up to 40 degrees
        width_shift_range=0.2,  # Horizontal shift
        height_shift_range=0.2,  # Vertical shift
        shear_range=0.2,  # Shear transformation
        zoom_range=0.2,  # Zoom
        horizontal_flip=True,  # Horizontal flip
        brightness_range=[0.8, 1.2],  # Brightness
        fill_mode='nearest'  # Fill mode
    )

    # Reshape the image to (1, height, width, 1) for the ImageDataGenerator
    image = image.reshape((1,) + image.shape + (1,))

    # generate a batch and use it for training
    for batch in datagen.flow(image, batch_size=1):
        return batch[0].reshape(image.shape[1:3])

# Filtering and Enhancement (Gaussian Blur)
def enhance_image(image):
    """Apply filtering and enhancement techniques."""
    # Gaussian Blur
    blurred = cv2.GaussianBlur(image, (5, 5), 0)
    return blurred

# Sample usage
image_path = df['lung_mask_path'].iloc[0]  # sample image path from your dataframe
original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
augmented = augment_image(original_image)
enhanced = enhance_image(augmented)

# Visualization
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(original_image, cmap='gray')
plt.title("Original Image")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(augmented, cmap='gray')
plt.title("Augmented Image")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(enhanced, cmap='gray')
plt.title("Enhanced Image")
plt.axis('off')

plt.show()

"""- The `augment_image` function leverages ImageDataGenerator to apply diverse data augmentation techniques to the input image. This generator is capable of creating a myriad of image variations based on the configured parameters. In this demonstration, we obtain a single augmented version for visualization purposes.

- The `enhance_image` function introduces the Gaussian blur as an enhancement technique. You can easily extend this function to incorporate other filtering and enhancement methods as needed.

- To facilitate comprehension of the applied transformations, we conclude by presenting a side-by-side visualization of the original, augmented, and enhanced images. This comparative visualization aids in understanding the modifications applied to the image.

# Image Filtering, Enhancement, and Feature Extraction:
"""

def apply_gaussian_blur(image):
    """Apply Gaussian blur to smoothen the image."""
    return cv2.GaussianBlur(image, (5, 5), 0)

def histogram_equalization(image):
    """Enhance image contrast using histogram equalization."""
    return cv2.equalizeHist(image)

def clahe_equalization(image):
    """Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)."""
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(image)

# Feature Extraction (using SIFT)

def extract_features(image):
    """Extract SIFT features from the image."""
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)
    return keypoints, descriptors

# Sample usage
image_path = df['lung_mask_path'].iloc[0]  # sample image path from your dataframe
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

blurred_image = apply_gaussian_blur(image)
equalized_image = histogram_equalization(image)
clahe_image = clahe_equalization(image)
keypoints, descriptors = extract_features(image)

# Visualization
plt.figure(figsize=(15, 4))
plt.subplot(1, 3, 1)
plt.imshow(equalized_image, cmap='gray')
plt.title("Histogram Equalized Image")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(clahe_image, cmap='gray')
plt.title("CLAHE Image")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(cv2.drawKeypoints(image, keypoints, None))
plt.title("SIFT Features")
plt.axis('off')

plt.show()

"""Image Filtering and Enhancement:

apply_gaussian_blur: Applies Gaussian blur to smoothen the image.
histogram_equalization: Enhances image contrast using histogram equalization.
clahe_equalization: Applies CLAHE (Contrast Limited Adaptive Histogram Equalization).
Feature Extraction (Using SIFT as an Example):

extract_features: Extracts SIFT features from the image. Note that other feature extraction methods like SURF, HOG, etc., can be used depending on the specific problem.
Visualization:

Showcases the histogram-equalized image.
Displays the CLAHE-processed image.
Presents the original image with SIFT keypoints drawn on it.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import draw

# SIFT
def extract_sift_features(image):
    """Extract SIFT keypoints and descriptors."""
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)
    return keypoints, descriptors

# HOG
def extract_hog_features(image):
    """Extract HOG features."""
    win_size = (64, 64)
    block_size = (16, 16)
    block_stride = (8, 8)
    cell_size = (8, 8)
    nbins = 9
    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)
    return hog.compute(image)

# HOG Visualization
def visualize_hog(image, hog_features, cell_size=(8, 8), bin_size=9):
    """Visualize HOG features on the given image."""
    num_cells_per_block = 2
    num_pixels_per_cell = cell_size[0]
    num_cells_x = image.shape[1] // num_pixels_per_cell
    num_cells_y = image.shape[0] // num_pixels_per_cell
    radius = cell_size[0] // 2 - 1
    orientations_arr = np.arange(bin_size)
    dx_arr = np.cos(orientations_arr * (np.pi / bin_size))
    dy_arr = np.sin(orientations_arr * (np.pi / bin_size))
    hog_image = np.zeros_like(image, dtype=float)
    for y in range(num_cells_y - 1):  # Subtracting 1 since we're considering 2x2 blocks
        for x in range(num_cells_x - 1):
            for o in range(bin_size):
                dx = dx_arr[o]
                dy = dy_arr[o]
                centre = tuple([y * num_pixels_per_cell + num_pixels_per_cell // 2,
                                x * num_pixels_per_cell + num_pixels_per_cell // 2])
                rr, cc = draw.line(int(centre[0] - dx * radius),
                                   int(centre[1] - dy * radius),
                                   int(centre[0] + dx * radius),
                                   int(centre[1] + dy * radius))
                hog_image[rr, cc] += hog_features[y, x, 0, 0, o]
    return hog_image / hog_image.max()  # Normalize the image for visualization

# Sample usage
image_path = df['lung_mask_path'].iloc[0]  # sample image path from your dataframe
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

sift_keypoints, sift_descriptors = extract_sift_features(image)
hog_features = extract_hog_features(image)

# Parameters for HOG reshaping
cell_size = (8, 8)
block_size = (2, 2)
nbins = 9
n_cells = (image.shape[0] // cell_size[0], image.shape[1] // cell_size[1])
n_blocks = (n_cells[0] - block_size[0] + 1, n_cells[1] - block_size[1] + 1)
total_elems = n_blocks[0] * n_blocks[1] * block_size[0] * block_size[1] * nbins

hog_features_arranged = hog_features[:total_elems].reshape(n_blocks[0], n_blocks[1], block_size[0], block_size[1], nbins).transpose((1, 0, 2, 3, 4))
hog_viz = visualize_hog(image, hog_features_arranged)

# Visualization
plt.figure(figsize=(20, 5))
plt.subplot(1, 3, 1)
plt.imshow(cv2.drawKeypoints(image, sift_keypoints, None))
plt.title("SIFT Keypoints")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(hog_viz, cmap='hot')
plt.title("HOG Visualization")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(image, cmap='gray')
plt.title("Original Image")
plt.axis('off')

plt.show()

"""SIFT Feature Extraction:
SIFT identifies and highlights distinctive keypoints in the image. These keypoints are chosen to ensure consistency across various transformations, making them valuable for tasks like object recognition and image stitching.
HOG Feature Extraction:

HOG captures structural information by analyzing the intensity gradients in the image. It breaks the image into cells, calculates gradients in each cell, and aggregates these gradients into histograms. These histograms represent the image's structural features.
Visualization:

The code provides visualizations of the key features extracted by SIFT and HOG.
These visualizations help users understand how these algorithms interpret and represent image content, aiding in the comprehension and debugging of the feature extraction process

# Data Splitting:
"""

from sklearn.model_selection import train_test_split
import pandas as pd

# Split the data into training and temporary test set
train_df, temp_test_df = train_test_split(df, test_size=0.4, stratify=df['class'], random_state=42)

# Split the temporary test set into validation and test set
valid_df, test_df = train_test_split(temp_test_df, test_size=0.5, stratify=temp_test_df['class'], random_state=42)

print(f"Train set size: {len(train_df)}")
print(f"Validation set size: {len(valid_df)}")
print(f"Test set size: {len(test_df)}")

"""# Image Data Augmentation:


"""

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
import os

# Define the data augmentation pipeline
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

sample_image_path = df.iloc[0]['lung_mask_path']
img = load_img(sample_image_path)
x = img_to_array(img)  # Convert the image to a numpy array
x = x.reshape((1,) + x.shape)  # Reshape the image

# Create a directory to save the augmented images
save_dir = "augmented_images/"
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

# Generate and save augmented images
i = 0
for batch in datagen.flow(x, batch_size=1, save_to_dir=save_dir, save_prefix='aug', save_format='jpeg'):
    i += 1
    if i > 20:  # Generate 20 augmented images for demonstration
        break

"""Configuration: Setting up an ImageDataGenerator with augmentation parameters.

Loading: Loading a sample image from a dataset and converting it into a numpy array.

Directory Setup: Creating a directory named "augmented_images" to save the augmented images.

Augmentation: Looping through batches of augmented images and saving them in JPEG format.

Limit: Generating and saving a maximum of 20 augmented images for demonstration.

# Data Loading and Combining:
"""

import os
import cv2
import numpy as np

# Load original images and labels from the DataFrame
original_images = []
original_labels = []

for index, row in df.iterrows():
    img = cv2.imread(row['lung_mask_path'], cv2.IMREAD_GRAYSCALE)
    original_images.append(img)
    original_labels.append(row['class'])

original_images = np.array(original_images)
original_labels = np.array(original_labels)

# Assuming augmented images are saved in 'augmented_images/' directory
augmented_dir = 'augmented_images/'

# Load augmented images
augmented_images = []
augmented_labels = []
for image_name in os.listdir(augmented_dir):
    img_path = os.path.join(augmented_dir, image_name)
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # or cv2.IMREAD_COLOR for color images
    augmented_images.append(img)
    augmented_labels.append(label)

augmented_images = np.array(augmented_images)
augmented_labels = np.array(augmented_labels)

# Combine with original data
combined_images = np.concatenate((original_images, augmented_images), axis=0)
combined_labels = np.concatenate((original_labels, augmented_labels), axis=0)

# Shuffle combined data
indices = np.arange(combined_images.shape[0])
np.random.shuffle(indices)

combined_images = combined_images[indices]
combined_labels = combined_labels[indices]

print("Combined Images Shape:", combined_images.shape)
print("Combined Labels Shape:", combined_labels.shape)

"""Loading Original Data:

Load original images and labels from the DataFrame.
Store them in original_images and original_labels.
Loading Augmented Data:

Load augmented images from the 'augmented_images/' directory.
Store them in augmented_images and augmented_labels.
Combining Data:

Concatenate original and augmented data into combined_images and combined_labels.
Shuffling Data:

Shuffle the combined dataset to randomize the order.
Data Shape Display:

Print the shapes of the combined images and labels arrays.

#Visualization of Combined Data:
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(12,6))
for i in range(6):
    plt.subplot(2,3,i+1)
    plt.imshow(combined_images[i], cmap='gray')  # Use cmap='gray' -images are grayscale
    plt.title(f"Label: {combined_labels[i]}")
    plt.axis('off')
plt.show()

"""# Data Splitting and Shuffling:


"""

indices = np.arange(combined_images.shape[0])
np.random.shuffle(indices)

combined_images = combined_images[indices]
combined_labels = combined_labels[indices]

from sklearn.model_selection import train_test_split

# Splitting into training and temporary sets
X_temp, X_test, y_temp, y_test = train_test_split(combined_images, combined_labels, test_size=0.2, stratify=combined_labels)

# Splitting the temporary set into actual train and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp)  # 0.25 x 0.8 = 0.2

"""# Model Building CNN

# Defining the model architecture
"""

import numpy as np
import cv2
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from keras.regularizers import l2  # Import L2 regularization

# Define the number of classes
num_classes = len(np.unique(combined_labels))

# Convert class labels to one-hot encoding
label_encoder = LabelEncoder()
y_encoded = to_categorical(label_encoder.fit_transform(combined_labels))

# Resize the images to match the model's input shape (128x128)
img_width, img_height = 128, 128
X_resized = np.array([cv2.resize(image, (img_width, img_height)) for image in combined_images])

# Initialize cross-validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
best_model = None
best_accuracy = 0

# Regularization parameter (you can adjust this)
l2_regularization = 0.001  # Experiment with different values

# Iterate through cross-validation folds
for fold_num, (train_index, test_index) in enumerate(kf.split(X_resized, combined_labels)):
    X_train, X_test = X_resized[train_index], X_resized[test_index]
    y_train, y_test = y_encoded[train_index], y_encoded[test_index]

    # Define the CNN architecture with L2 regularization
    model = Sequential()

    # First convolutional layer with L2 regularization
    model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 1), kernel_regularizer=l2(l2_regularization)))  # Assuming grayscale images
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Second convolutional layer with L2 regularization
    model.add(Conv2D(32, (3, 3), kernel_regularizer=l2(l2_regularization)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Third convolutional layer with L2 regularization
    model.add(Conv2D(64, (3, 3), kernel_regularizer=l2(l2_regularization)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Flatten and pass to the dense layers
    model.add(Flatten())
    model.add(Dense(64, kernel_regularizer=l2(l2_regularization)))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, kernel_regularizer=l2(l2_regularization)))
    model.add(Activation('softmax'))

    # Compile the model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Train the model with progress indicator
    batch_size = 32  # Adjust based on dataset size and memory capacity
    history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_split=0.2, verbose=1)

    # Evaluate the model on the test data for this fold
    _, test_accuracy = model.evaluate(X_test, y_test)
    print(f"Fold {fold_num + 1} - Test Accuracy: {test_accuracy * 100:.2f}%")

    # Check if this model performs better than the previous best
    if test_accuracy > best_accuracy:
        best_accuracy = test_accuracy
        best_model = model

# Evaluate the best model on the entire test set
test_loss, test_accuracy = best_model.evaluate(X_resized, y_encoded)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")